<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="assets/ico/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Sans" rel="stylesheet">

    <title>Jaeyoon Jung - Algorithmic Attribution Model</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">

  </head>

  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="index.html#page-top">
        <span class="d-block d-lg-none">Start Bootstrap</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.JPG" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#projects">Projects</a>
          </li>
        </ul>
      </div>
    </nav>

    <header class="masthead" style="background-image: url('img/work.jpg')">
            <div class="container">
                <div class="row">
                    <div class="project-header col-lg-12 col-lg-offset-0">
                        <h1>Algorithmic Attribution Model</h1>
                        <h4>
                            Qunatifying performance of online marketing campaigns
                        </h4>
                    </div>
                </div>
            </div>
    </header>

    <section class="p-3 p-lg-5 d-flex flex-column" id="summary">
      <div class="my-auto" align="center">
        <div class="resume-item d-flex flex-column flex-md-row mb-5 col-lg-10" style="text-align: left;">
          <div class="resume-content mr-auto">
            <h2 class="mb-1">ABOUT THIS PROJECT</h2>
            <br>
            <p>
                As one of my summer capstone projects at DigitalOcean, I designed and
                implemented an algorithmic attribution model. Specifically, I implemented a model that
                analyzes customer journey data as a higher-order Markov process. Prior to this project,
                the company had a very complicated custom rule-based model, and there had been
                no formal evaluation on it. By framing the problem as a classification task,
                I scientifically evaluated and compared performance of the company's exisiting model,
                linear and last touch models, and my Markov model.
            </p>
            <br>
            <h3 class="mb-1">Background</h3>
            <br>
            <p>
                Many companies with online presence invest a significant amount of their go-to-market
                budget in online marketing campaigns to acquire new users. <i>Channels</i>, or
                <i>touchpoints</i>, could be any online message through which customers interact with
                the brand. Email campaigns, display ads, ratargeting ads, and non-brand search
                engine marketing are all examples of such touchpoints. An important aspect of web analytics
                is to understand performance of each marketing campaigns- how many conversions does each
                marketing channel create?
            </p>
            <p>
                This sounds like a simple question. However, the answer becomes a lot more complicated,
                because most customers go through multiple touchpoints, like this:
            </p>
            <center>
                <img class="img" src="img/attribution/multitouch.png" width="500" height ="150">
            </center>
            <br>
            <p>
                In an example like this, how do we know contribution of each touchpoint? Are some
                more important than others? Marketing/analytics teams use <b>attribution models</b>
                to answer such questions, and traditional models are <b>heuristic</b> models that are
                based certain rules that follow prior assumptions about relative weight.
                For example, a <i>last touch model</i>
                gives 100% of credit to the last touchpoint a customer interacts with. Another heuristic model,
                <i>linear model</i>, assumes that all touchpoints make equal contribution to conversion
                events. In the example path above, a last touch model will say that Partnerships contributed in
                1 conversion. On the other hand, a linear model would attribute 0.33 conversion to each channel.
                Here are some common attribution models:
            </p>
            <center>
                <img class="img" src="img/attribution/common_attribution.png" width="600" height ="400">
            </center>
            <br>
            <p>
                When I joined DigitalOcean, the company was using a custom rule-based attribution model,
                based on very complicated rules. I won't elaborate what the exact heuristics are, but
                in short, it's a U-shaped graph that gives some weight to the first touch and splits
                the rest like a time decay model does. Just as in other heuristic models, the initial weights
                and specific rules are also based on intuition, not data. More importantly, there was no way
                of telling how well it performed- there had been no formal evaluation on this model at all.
            </p>
            <p>
                Given that the company has been increasing its spend on user acquisition,
                it is important to have a good attribution model so that the marketing team can better
                estimate customer acquisition cost and optimize ROI. I also wanted my stakeholders to
                get into the culture of validating analytical models. Without a proper evaluation framework,
                they cannot justify their choices of models with objectivity. Hence, I had two goals for this project:
            </p>
            <ol>
                <li>
                    Based on population of new users, find statistical relationship between usersâ€™
                    conversion and marketing channels
                </li>
                <li>
                    Establish a scientific framework to evaluate and compare models
                </li>
            </ol>
            <br>
            <h3 class="mb-0">Markov Attribution Model</h3>
            <br>
            <p>
                Instead of choosing a set of arbitrary rules, I wanted to tune weights based on
                popoulation statistics. Thus, I chose </b>Markov attribution model</b>, a well-known
                algorithmic attribution model that treats customer journey as a Markov process.
                Markov theory is based on two fundamental assumptions:
            </p>
            <ol>
                <li>
                    Markov Property: P{ X<sub>i</sub> = x<sub>i</sub> | X<sub>i-1</sub> =
                        x<sub>i-1</sub>, X<sub>i-2</sub> = x<sub>i-2</sub>...,X<sub>0</sub> =
                        x<sub>0</sub> } = P{ X<sub>i</sub> = x<sub>i</sub> | X<sub>i-1</sub> = x<sub>i-1</sub>,...,
                        X<sub>i-n</sub> = x<sub>i-n</sub> }
                </li>
                <li>
                    Time-homogenous: P{ X<sub>i+1</sub> = j | X<sub>i</sub> = k } is the same for all n = 0,1,2,...
                </li>
            </ol>
            <p>
                Here, X represents touchpoints. According to these two assumptions, given
                a path of touchpoints a user has visited, the probability of visiting
                touchpoint X next depends only on the last n touchpoints visited. When n >= 1, the model
                adds memory and complexity by considering interaction and order among channels as well.
                With this framework, we represent all steps in customer journeys in a graph, and compute
                transition probability between nodes (probability of visiting a certain touchpoint
                from a series of n steps)
            </p>
            <center>
            <p>
                Transition Probability = P{ X<sub>i</sub> = x<sub>i</sub> | X<sub>i-1</sub> = x<sub>i-1</sub>,..., X<sub>i-n</sub> = x<sub>i-n</sub> }
            </p>
            </center>
            <p>
                For example, in a simple model where n = 1 (only considers the previous touchpoint visited),
                the graph may look like this:
            </p>
            <center>
                <img class="img" src="img/attribution/graph1.png" width="550" height ="300">
            </center>
            <p>
                Then, the model does the following:
            </p>
            <ol>
                <li>
                    Compute the probability of eventually reaching <i>Conversion</i> node,
                    given that the user is at <i>Start</i> node.
                </li>
                <li>
                    Recompute the same probability, with a channel removed from the graph
                </li>
                <li>
                    Calculate decrease in probability of conversion (also known as Removal Effect).
                </li>
                <li>
                    After repeating Step 1~3 for each channel, scale each removal effect by the total sum-
                    this outcome is a percentage attribution of a channel
                </li>
            </ol>
            <center>
                <img class="img" src="img/attribution/graph2.png" width="550" height ="300">
            </center>
            <p>
                That's it! The intuitive explanation for the model is that it measures the
                relative attribution by observing how the behavior of the overall population
                changes when a channel is removed. For example, even if a channel appears in a lot of customer
                journeys, if it does not have much impact on conversion probability, the model
                does not give it much weight. On the other hand, heuristic models may end up giving the same touchpoint
                a lot of credit, since it's counting sheer occurences of each channel.
                I decided that Markov model is better suited for attribution analyses
                than heuristic models are, because 1. all weights are tuned based on population statistics;
                2. higher-order model (when n > 1) considers <i>interaction</i> among touchpoints;
                3. it has a predictive power and thus can be validated and scored.
            </p>
            <p>
                I wrote a parent class that implements Markov Chain for general use
                and a child class that inherits it to build an attribution model for DigitalOcean.
                All work was done in Python.
            </p>
            <br>

            <h3 class="mb-0">Data</h3>
            <br>
            <p>
                An interesting challenge of building a probabilistic model is that it uses
                <b>right-censored</b> data. The model requires data of both conversion and non-conversion
                events, but it is impossible to retrieve coherent session data and map it to right
                users if they never signed up for DigitalOcean accounts. Luckily, the company defines
                conversion as customers launching our core product, <i>Droplet</i>, for the
                first time. Therefore, I assumed that those who had signup records but never launched Droplet
                represent non-conversion events. This turned out to be a reasonable assumption, because exploratory
                analysis of session data shows that 95% of users created their first Droplet within
                <i>x</i> days of signing up.
            </p>
            <p>
                Unfortunately, I cannot disclose specific details of the data :(
            </p>
            <br>
            <h3 class="mb-0">Evaluation</h3>
            <br>
            <p>
                One important aspect of this project was to establish an evaluation framework to not only
                compare performance of the new and existing models, but also to log model scores over time
                to ensure we maintain the quality of our work. Classification tasks often use accuracy has an
                evaluation metric. However, in online marketing, there are a lot more non-conversion events (
                negative class) than conversion events (positive class). Because of such a class imbalance,
                accuracy can be very misleading, because a model can achieve a very good score, if it simply
                does well with the negative class or, in an extreme case, classifies everything negative.
                Therefore, instead of accuracy, I chose to use the following three different metrics:
            </p>
            <ol>
                <li>
                    <b>Recall</b>
                    <p>
                        <i>True Positives / (True positives + False Negatives)</i>. From the marketing
                        team's perspective, it's much more important for the model to capture conversion events correctly
                        than to capture non-conversion events, so that the company can
                        reach out to as many potential customers as possible.
                    </p>
                </li>
                <li>
                    <b>Precision</b>
                    <p>
                        <i>True Positives / (True positives + False Positives)</i>. Although we do want a model
                        with high recall, it would be useless if it simply predicts everything
                        positive and achieves a score of 1. Precision tells us how balanced our predictions
                        are.
                    </p>
                <li>
                    <b>ROC AUC (Receiver Operating Characteristics Area Under the Curve)</b>
                    <p>
                        Given predicted probabilities of a model, the ROC curve plots how
                        false positive rates (x-axis) and true positive rates (y-axis) change
                        over different classification thresholds. Ideally, we want to have a
                        model that not only predicts everything correctly but also separates
                        the two classes very well. A good model predicts all positives with
                        probability near 1 and negatives with probability near 0, as opposed to
                        predicting everything between 0.49 and 0.51, for example. To turn ROC
                        into a scalar measure, we compute AUC (Area under the curve) as a final
                        score. The maximum AUC is 1, and we want to achieve highest AUC possible-
                        even if a model has good recall and precision, if it does not distinguish
                        predicted probabilities of two classes well, it will not be very robust
                        against new data. Thus, ROC AUC tells us quality of classifications.
                    </p>
                </li>
            </ol>
            <center>
                <img class="img" src="img/attribution/roc_example.png" width="400" height ="400">
                <p>source: scikit learn</p>
            </center>
            <p>
                With these metrics, I compared performance of DigitalOcean's custom
                model, last touch model, linear model, and markov models up to 4th order.
                I cross-validated the models using 5 stratified folds to address class imbalance issue.
            </p>
            <br>
            <h3 class="mb-0">Result</h3>
            <br>
            <p>
                The table below shows average recall, precision, and ROC AUC for a cohort of
                users. Unfortunately, I cannot share the attribution chart
                (bar graph showing number of conversions per channel) that each model produced.
            </p>
            <table class="table table-striped">
                <thead class="thead-default">
                    <tr>
                        <th>Models</th>
                        <th>Recall</th>
                        <th>Precision</th>
                        <th>ROC AUC</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Last Touch</td>
                        <td>0.574</td>
                        <td>0.336</td>
                        <td>0.613</td>
                    </tr>
                    <tr>
                        <td>Linear</td>
                        <td>0.742</td>
                        <td>0.323</td>
                        <td>0.600</td>
                    </tr>
                    <tr>
                        <td>DO's Custom Model</td>
                        <td>0.708</td>
                        <td>0.319</td>
                        <td>0.595</td>
                    </tr>
                    <tr>
                        <td>1st Order Markov</td>
                        <td>0.760</td>
                        <td>0.361</td>
                        <td>0.703</td>
                    </tr>
                    <tr>
                        <td><b>2nd Order Markov</b></td>
                        <td><b>0.731</b></td>
                        <td><b>0.371</b></td>
                        <td><b>0.712</b></td>
                    </tr>
                    <tr>
                        <td>3rd Order Markov</td>
                        <td>0.604</td>
                        <td>0.411</td>
                        <td>0.718</td>
                    </tr>
                    <tr>
                        <td>4th Order Markov</td>
                        <td>0.581</td>
                        <td>0.421</td>
                        <td>0.719</td>
                    </tr>
                </tbody>
            </table>
            <br>
            <p>
                At the end of this, I concluded that the 2nd order Markov model is the best performing
                model overall. Strictly speaking, the 4th order Markov model has the best ROC AUC score.
                However, its score is only marginally higher than that of the 3rd order model, and this
                improvement comes at the expense of recall. Furthermore,
                although the 1st and 2nd order Markov models have much higher recall than the original model
                does, the score significantly decreases with 3rd and 4th order models. In fact, as the order,
                increases, the dimensionality of data increases exponentially- thus the model becomes too
                specific and cannot perform well with new data. On the other hand, the 2nd order model has
                much higher ROC AUC than hueristic models do, while maintaining a fairly high recall score.
            </p>
            <p>
                At the end of my time at DigitalOcean, I was able to provide the company's first
                algorithmic attribution model, and rigorously evaluate the results with a scientific
                validation method. The final deliverables included python modules, SQL script, and
                executable that populates the database with attribution per channel and evaluation scores.
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
