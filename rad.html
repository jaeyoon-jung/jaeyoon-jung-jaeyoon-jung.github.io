<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="assets/ico/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Sans" rel="stylesheet">

    <title>Jaeyoon Jung - Rotten Apple Detector (RAD)</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">

  </head>

  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="index.html#page-top">
        <span class="d-block d-lg-none">Jaeyoon Jung</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.JPG" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="index.html#projects">Projects</a>
          </li>
        </ul>
      </div>
    </nav>

    <header class="masthead" style="background-image: url('img/work.jpg')">
            <div class="container">
                <div class="row">
                    <div class="project-header col-lg-12 col-lg-offset-0">
                        <h1>RAD Image Recognition</h1>
                        <h4>Deep learning model that detects inappropriate images</h4>
                    </div>
                </div>
            </div>
    </header>

    <section class="p-3 p-lg-5 d-flex flex-column" id="summary">
      <div class="my-auto" align="center">
        <div class="resume-item d-flex flex-column flex-md-row mb-5 col-lg-10" style="text-align: left;">
          <div class="resume-content mr-auto">
            <h2 class="mb-1">ABOUT THIS PROJECT</h2>
            <br>
            <p>
                Rotten Apple Detector, aka RAD, is a product that my team developed for Criteo's internal hackathon
                held across 20 offices globally. The goal of the project was to create a tool that filters out listings with inappropriate
                descriptions or images in our clients' feed via keyword search and image recognition. I assessed potential business value of our project and developed
                an image classifier, while other teammates deployed a solution for keyword match in Japanese and Chinese.
                The team won the 2nd place in APAC region.
            </p>
            <p>
                For the final model, I deployed a machine learning model with deep-learned features, using TensorFlow's
                Inception V3 (CNN architecture) and XGBoost.
            </p>
            <br>
            <h3 class="mb-0">MOTIVATION</h3>
            <br>
            <p>
                When advertisers include products with inappropriate descriptions or images in their feed, they end up getting
                blacklisted by publishers. Blacklisting incidents damage performance of advertisers' campaigns and Criteo's relationship
                with other publishers, eventually costing the company a large amount of revenue. This is a particularly notable
                problem in Asia, because regular keyword match algorithms do not work well with syntactic structure of Japanese
                and Chinese language. The analysis of publisher share of voice and advertiser revenue estimates that Criteo can gain a
                potential revenue uplift of 4.5% and 6.3% in Japan and China respectively, if it can resolve all blacklisting issues.
            </p>
            <p>
                Currently, responsibilities of keeping bad products out of feed are all on advertisers,
                and there is no comprehensive solution within Criteo's ecosystem. The objective of this project is to
                develop a solution to blacklisting problems through automatic detection of bad (inappropriate) keywords and images.
            </p>
            <br>
            <h3 class="mb-0">RAD Solution</h3>
            <br>
            <p>
                My team's solution, Rotten Apple Detector, is a 2-part solution.
            </p>
            <ol>
              <li>Enhanced Exact Match: Criteo does have an internal method of detecting products that contain
                  exact match of bad keywords. However, it does not work for Japanese and Chinese because they do not
                  have spaces. We used natural language processing to better tokenize words in languages without spaces.</li>
              <li>Image Recognition: there is no tool to detect inappropriate images during feed integration. Our solution was to
                build a deep learning model that can recognize such images. </li>
            </ol>
            <p>My responsibilities within the team were</p>
            <ol>
              <li>Assessment of Business Value</li>
              <li>Development of the second part of RAD solution; image recognition model</li>
            </ol>
            <br>
            <h3 class="mb-0">Data</h3>
            <br>
            <p>
                The biggest limitation of building an image recognition model was availability of data. Of course, as a company
                whose engine is driven by big data and machine learning, Criteo has a very rich data infrastructure. However,
                as an analyst of a regional office (Tokyo), I did not have access to the company's image database. Thus,
                instead of working on a complete product that can be deployed right away, I built a model with samples of
                'bad' categories to pitch a proof of concept.
            </p>
            <p> The three categories are: </p>
            <uo>
              <li>Gun: many publishers do not allow display of weapons </li>
              <li>Knife: same as above </li>
              <li>Nudity: Criteo as a whole does not allow any sexual contents. In this context,
                          I defined nudity as very revealing images in general, not strict nudity. </li>
            </uo>
            <p>
              Then, the model was trained to classify images into 4 categories: Good Product, Gun, Knife, and Nudity.
              Data for bad categories were collected by batch-downloading 400 images per class from Google.
              For good products, I randomly downloaded 400 images from Criteo's internal platform, to include a variety of products.
            </p>
            <br>
            <h3 class="mb-0">Methodology / Model Architecture</h3>
            <br>
            <p>
                <b>TL;DR</b>- Transfer learning on a pre-trained Convolutional Neural Network model (Inception V3 Architecture),
                with a final layer of fitting an XGBoost model on output features.
            </p>
            <br>
            <p>
                For theoretircal understanding of CNN architecture, Stanford's reading materials on
                <a href="http://cs231n.github.io/convolutional-networks/">CS231n: Convolutional Neural Networks for Visual Recognition</a> were
                immensely helpful. For implementation, I used <a href="https://www.tensorflow.org/">TensorFlow</a>.
            </p>
            <br>
            <p>
                To build an image recognition model that can be trained on dataset with 'inappropriate' products,
                I used a Convolutional Neural Network (CNN) as a main algorithm to idenitfy image features.
                Specifically, I applied transfer learning, which is a method of preserving the
                architecture of a pre-trained model but re-training it on a new dataset with desired classes. The key assumption
                that comes with transfer learning is that features useful in identifying one class can be useful for
                characterizing other classes as well. For eaxmple, if a model is trained to distinguish angular objects from round ones,
                a feature answering a question of 'Does the object have a straight edge?' is useful for training a facial
                recognition model, for human faces generally have oval shapes.
            </p>
            <p>
                Although transfer learning is not as accurate as fully training a new CNN architecture,
                it is generally known to have very good performance. This method was also appropriate for this Hackathon,
                given the following conditions:
                </p>
            <ul>
              <li>Because I could not access Criteo's data infrastructure, the model would have to be redesigned and retrained with a
                  refined dataset for real production anyway.</li>
              <li> Even with a perfect training dataset, my laptop alone cannot handle a complete training without GPU</li>
              <li>I had 48 hours for this Hackahton.</li>
              <li>Proof of concept, rather than a fully developed solution, would be sufficient for pitch & demo. </li>
            </ul>
            <p>
                The base model I chose was Inception V3 model. It is a type of CNN model that was trained on Imagenet dataset,
                a standard academic dataset with 1000 classes commonly used for training an image recognition model.
                In the original model, the layer right before the final classification layer returns a 2048 dimensional vector (in float),
                which essentially represents 2048 features of an image. Therefore, to extract high-level features of
                my training data (good products, nudity, gun, and knife images), I took the output of this feature vector from
                Inception V3 Model. Then, instead of using the original final layer, I added a custom layer,
                in which I applied PCA on 2048 deep-learned numeric features and used 100 reduced features
                to fit an XGBoost model.
            </p>
            <br>
            <h3 class="mb-0">Result</h3>
            <br>
            <p> When validated with K-Fold cross validation with 5 folds (20% split for test data),
                the model achieved accuracy of approximately 95.5%. Below is a confusion matrix of the 5-fold validation:
            </p>
            <center>
              <img src="img/rad/confusion_matrix.png" width="600" height ="500"></img>
            </center>
            <br>
            <br>
            <h3 class="mb-0">Image Detection Demo</h3>
            <br>
            <p>
                For the demo, I demonstrated the performance of the model using real product images from Criteo's feed.
                Out of 3 good products, 2 knives, 2 nudity, and 2 guns, the model classified 8/9 images correctly.
                Because of constraints on time and data access, I could not create an additional test dataset that strictly consists of
                Criteo's product images.
            </p>
            <br>
            <center>
              <video width="720" height="400" controls>
                <source src="img/rad/RAD_Demo.mp4" type="video/mp4">
              </video>
            </center>
          </div>
        </div>
      </div>
    </section>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
